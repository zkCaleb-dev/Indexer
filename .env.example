# Stellar RPC Server URL
# Testnet: https://soroban-testnet.stellar.org
# Mainnet: https://soroban-mainnet.stellar.org
RPC_SERVER_URL=https://soroban-testnet.stellar.org

# Network Passphrase
# Testnet: Test SDF Network ; September 2015
# Mainnet: Public Global Stellar Network ; September 2015
NETWORK_PASSPHRASE=Test SDF Network ; September 2015

# Starting ledger sequence (0 = start from latest)
START_LEDGER=0

# Buffer size for RPC ledger retrieval
# Controls how many ledgers are pre-fetched in memory before processing
# Higher values improve throughput but use more memory (~1MB per ledger)
#
# Recommended values based on use case:
#   50  = Low memory environments (< 4GB RAM), ~5 min buffer
#   150 = Optimal balance (4-8GB RAM), ~12.5 min buffer - RECOMMENDED
#   200 = High performance (> 8GB RAM), ~16 min buffer
#   300 = Maximum throughput with fast network, ~25 min buffer
#
# Note: With optimizations (batch INSERT, ChangeCompactor), processing is fast
# so a larger buffer prevents waiting for ledgers from RPC server
BUFFER_SIZE=150

# Factory contracts (STRKEY format - starts with C)
FACTORY_CONTRACT_SINGLE_RELEASE_ID=CDQPREX7KCYB4KBGSVYOUUMQ5FXT6R4NO6R3LLXUUK3FODVBY2FKNTMZ
FACTORY_CONTRACT_MULTI_RELEASE_ID=CCAJPWPKSR6FY5Q5RYT5E3EIZQNDMDFYVVKJ656C5SUOIXQOQ4JQVWGV

# Logging configuration
# Levels: debug, info, warn, error
LOG_LEVEL=info

# Database configuration
# PostgreSQL connection string
DATABASE_URL=postgresql://indexer:indexer_dev_password@localhost:5433/stellar_indexer?sslmode=disable

# HTTP Client configuration (Connection Pooling & Timeouts)
# Optimized for continuous RPC streaming
HTTP_TIMEOUT_SEC=60                    # Request timeout in seconds
HTTP_MAX_IDLE_CONNS=100                # Max idle connections across all hosts
HTTP_MAX_CONNS_PER_HOST=100            # Max connections per host
HTTP_IDLE_CONN_TIMEOUT_SEC=90          # Idle connection timeout in seconds

# Progress Checkpointing
# Save progress every N ledgers for resume capability
# Set to 0 to disable checkpointing
CHECKPOINT_INTERVAL=100                # Save progress every 100 ledgers

# API Server
# HTTP server port for Prometheus metrics and REST API endpoints
#
# Endpoints provided:
#   GET /            - Service information
#   GET /health      - Health check (returns {"status": "healthy"})
#   GET /metrics     - Prometheus metrics (for monitoring/alerting)
#
# You can add your own REST API endpoints in internal/api/handlers.go
API_SERVER_PORT=2112

# Parallel Processing Pipeline
# Enables parallel ledger processing for faster catch-up after downtime
#
# How it works:
#   - Normal operation (lag < 10): Sequential mode (simple, stable)
#   - After downtime (lag > 100): Auto-enables parallel mode (4x faster catch-up)
#   - Caught up (lag < 10): Auto-disables parallel mode
#
# Configuration:
ENABLE_PARALLEL_PROCESSING=true    # Enable pipeline (true/false)
PIPELINE_WORKER_COUNT=0             # Worker count (0 = auto-detect: 75% of CPU cores)
PIPELINE_BUFFER_SIZE=50             # Buffer between pipeline stages
AUTO_ENABLE_LAG_THRESHOLD=100       # Auto-enable if behind > 100 ledgers
AUTO_DISABLE_LAG_THRESHOLD=10       # Auto-disable if behind < 10 ledgers
#
# Example scenarios:
#   - Downtime of 2 hours = ~1440 ledgers behind
#   - Sequential mode: 48 min to catch up
#   - Parallel mode (4 workers): 12 min to catch up (4x faster)
#
# Note: Pipeline uses more RAM (~2x) but only when catching up